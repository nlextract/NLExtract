# Example of process-chains for extracting IMGeo source data from GML to PostGIS.
# A Chain is a series of Components: one Input, zero or more Filters and one Output.
# The output of a Component is connected to the input of the next Component (except for
# the final Output Component, which writes to the final destination, e.g. Postgres.
#
# Currently 3 chains are executed in the following order:
# - SQL pre:  DB initialization, delete tables, create schema
# - Main ETL chain, consists of the following components
# 1. input_zip_file: reads files from input ZIP file(s)
# 2. extract_zip_file: extracts a GML file from a ZIP file
# 3. output_ogr2ogr: output using ogr2ogr, input is a transformed GML file, output can be any OGR output
# - SQL post:  remove duplicates
#
# Any substitutable values are specified in curly brackets e.g. {password}.
# Actual values can be passed as args to Stetl main.py or as arguments from a wrapper program
# like imgeo-extract.py to etl.py. Here are the 3 chains:

[etl]
# Let op: dit werkt alleen op Windows. Ook moet de "xml.exe" van XMLStarlet in het pad staan!
# The ZIP file containing the GML files is "reused" multiple times by splitting the chain. The files
# are only extracted once. Before it is being loaded, a temporary GML file is being analyzed by
# ogr2ogr, so the actual feature type can be determined, the number of features can be counted. With
# this information the GFS file is being modified. When it only contains the actual feature type as
# well as the expected number of features, loading will be much faster. Although parsing the GML
# before by ogrinfo takes some time, the net benefit is very large, up to a factor of three during
# tests!
chains = input_sql_pre|schema_name_filter|output_postgres,
         input_zip_file|extract_zip_file|(output_std)
                                         (ogrinfo_command_generator|command_executor|ogrinfo_regex_filter|input_xsl_prep_gfs|output_xsl_prep_gfs)
                                         (xslt_command_generator|command_executor|output_prepped_gfs)
                                         (output_ogr2ogr)
										 (del_temp_files_command|command_executor|output_std),
         input_dummy_zip_file|extract_dummy_zip_file|output_ogr2ogr_init,
         input_sql_post|schema_name_filter|output_postgres

# alternative chains for testing
#chains = input_big_gml_files|xml_assembler|transformer_xslt|output_ogr2ogr,
#     input_big_gml_files|xml_assembler|transformer_xslt|output_std,
# chains=input_big_gml_files|xml_assembler|transformer_xslt|output_multifile

[ogrinfo_command_generator]
class = filters.templatingfilter.StringTemplatingFilter
template_string = ogrinfo -ro -al -so {temp_dir}/fromzip-tmp.gml

[command_executor]
class = filters.execfilter.CommandExecFilter

[ogrinfo_regex_filter]
class = filters.regexfilter.RegexFilter
pattern_string = .*Layer name: (\w+:)?(?P<elemtype>\w+).*Feature Count: (?P<featurecount>[0-9]+).*

[input_xsl_prep_gfs]
class = filters.templatingfilter.StringTemplatingFilter
template_string = <?xml version="1.0" encoding="UTF-8"?>
  <xsl:stylesheet version="1.0" xmlns:xsl="http://www.w3.org/1999/XSL/Transform">
    <xsl:output method="xml" version="1.0" encoding="utf-8" indent="yes" omit-xml-declaration="yes"/>
    <xsl:strip-space elements="*"/>
    <xsl:template match="/ | @* | node()">
        <xsl:copy>
            <xsl:apply-templates select="@* | node()" />
        </xsl:copy>
    </xsl:template>
    <xsl:template match="GMLFeatureClass">
        <!-- Filter on particular element -->
        <xsl:if test="ElementPath/text()='$elemtype'">
            <xsl:copy>
                <xsl:apply-templates select="@* | node()" />
            </xsl:copy>
        </xsl:if>
    </xsl:template>
    <xsl:template match="DatasetSpecificInfo">
        <xsl:copy>
            <!-- Add feature count -->
            <FeatureCount>$featurecount</FeatureCount>
            <xsl:apply-templates select="@* | node()" />
        </xsl:copy>
    </xsl:template>
  </xsl:stylesheet>
safe_substitution = True

[output_xsl_prep_gfs]
class = outputs.fileoutput.FileOutput
file_path = {temp_dir}/imgeo-prep-gfs.xsl

# TODO: python script maken die XSLT en XML accepteert en output teruggeeft
[xslt_command_generator]
class = filters.templatingfilter.StringTemplatingFilter
template_string = xml tr {temp_dir}/imgeo-prep-gfs.xsl gfs/imgeo-v2.1.1.gfs

[output_prepped_gfs]
class = outputs.fileoutput.FileOutput
file_path = {temp_dir}/prepped.gfs

# TODO: python script?
[del_temp_files_command]
class = filters.templatingfilter.StringTemplatingFilter
template_string = cleanup.cmd

# Pre SQL file inputs to be executed
[input_sql_pre]
class = inputs.fileinput.StringFileInput
file_path = sql/drop-tables-v2.1.1.sql,sql/create-schema.sql

# Post SQL file inputs to be executed
[input_sql_post]
class = inputs.fileinput.StringFileInput
file_path = sql/create-final-tables-v2.1.1.sql

# Generic filter to substitute Python-format string values like {schema} in string
[schema_name_filter]
class = filters.stringfilter.StringSubstitutionFilter
# format args {schema} is schema name
format_args = schema:{schema}

[output_postgres]
class = outputs.dboutput.PostgresDbOutput
database = {database}
host = {host}
port = {port}
user = {user}
password = {password}
schema = {schema}

# The source input ZIP-file(s) from dir, producing 'records' with ZIP file name and inner file names
[input_zip_file]
class=inputs.fileinput.ZipFileInput
file_path = {input_dir}
filename_pattern = *.[zZ][iI][pP]

# Filter to generate the vsizip-names
[vsizip_filter]
class=filters.templatingfilter.StringTemplatingFilter
template_string = /vsizip/$file_path/$name

# Filter to extract a ZIP file one by one to a temporary location
[extract_zip_file]
class=filters.zipfileextractor.ZipFileExtractor
file_path = {temp_dir}/fromzip-tmp.gml
delete_file = False

# The ogr2ogr command-line, may use any output here, as long as
# the input is a GML file. The "temp_file" is where etree-docs
# are saved. It has to be the same file as in the ogr2ogr command.
# TODO: find a way to use a GML-stream through stdin to ogr2ogr
[output_ogr2ogr]
class = outputs.execoutput.Ogr2OgrExecOutput
# destination format: OGR vector format name
dest_format = PostgreSQL
# destination datasource: name of datasource
dest_data_source = "PG:dbname={database} host={host} port={port} user={user} password={password} active_schema={schema}"
# layer creation options will only be added to ogr2ogr on first run
lco = -lco LAUNDER=YES -lco PRECISION=NO
# spatial_extent, translates to -spat xmin ymin xmax ymax
spatial_extent = {spatial_extent}
# gfs template
gfs_template = {temp_dir}/prepped.gfs
# miscellaneous ogr2ogr options
options = -append -gt 65536 {multi_opts}
# cleanup input?
cleanup_input = True

[input_dummy_zip_file]
class=inputs.fileinput.ZipFileInput
file_path = data
filename_pattern = dummy.zip

[extract_dummy_zip_file]
class=filters.zipfileextractor.ZipFileExtractor
file_path = {temp_dir}/dummy.gml
delete_file = False

# Initialization of all tables with empty file
# Note that this is done _after_ loading all the data, since this way the ETL is much faster.
[output_ogr2ogr_init]
class = outputs.execoutput.Ogr2OgrExecOutput
dest_format = PostgreSQL
dest_data_source = "PG:dbname={database} host={host} port={port} user={user} password={password} active_schema={schema}"
gfs_template = gfs/imgeo-v2.1.1.gfs
options = -append -gt 65536 {multi_opts}
cleanup_input = True

# Validator for XML
[xml_schema_validator]
class = filters.xmlvalidator.XmlSchemaValidator
xsd = http://schemas.geonovum.nl/imgeo/2.1/imgeo-2.1.1.xsd
enabled = False

# Below Alternative outputs for testing

# Send to stdout
[output_std]
class = outputs.standardoutput.StandardOutput

[output_file]
class = outputs.fileoutput.FileOutput
file_path = test/output/imgeo-fc.gml

# Output multiple files ala IMGeo file chunks GML
# Use numbering as in file expression.
[output_multifile]
class = outputs.fileoutput.MultiFileOutput
file_path = test/output/imgeo-%03d.gml

